services:
  # ===================================
  # BACKEND TypeScript – Express + Supabase
  # ===================================
  backend:
    build:
      context: ./backend-ts
      dockerfile: Dockerfile
    container_name: siprems-backend-ts
    restart: unless-stopped
    ports:
      - "8000:8000"
    env_file:
      - ./backend-ts/.env
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - ML_SERVICE_URL=http://ml-service:8001
      - PORT=8000
    depends_on:
      ml-service:
        condition: service_healthy
    networks:
      - frontend-net
      - backend-net
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.50'

  # ===================================
  # ML SERVICE Python – Prophet Models
  # ===================================
  ml-service:
    build:
      context: ./ml-service
      dockerfile: Dockerfile
    container_name: siprems-ml-service
    restart: unless-stopped
    ports:
      - "8001:8001"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - PORT=8001
    volumes:
      - model_data:/app/models
    networks:
      - backend-net
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  # ===================================
  # FRONTEND – React/Vite
  # ===================================
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
      target: development # Toggle to "production" for production mode
    container_name: siprems-frontend
    restart: unless-stopped
    ports:
      - "3000:3000"
    volumes:
      - ./src:/app/src
      - ./public:/app/public
      - ./vite.config.mts:/app/vite.config.mts
      - ./index.html:/app/index.html
    environment:
      - VITE_API_BASE_URL=http://localhost:8000/api
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - frontend-net

  # ===================================
  # RETRAIN SCHEDULER
  # ===================================
  retrain-scheduler:
    build:
      context: ./ml-service # Fixed context (was non-existent ./backend)
      dockerfile: Dockerfile # Reuse ML Dockerfile or specific one if needed
    container_name: siprems-retrain-scheduler
    restart: unless-stopped
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - ML_SERVICE_URL=http://ml-service:8001
    depends_on:
      ml-service:
        condition: service_healthy
    networks:
      - backend-net
    profiles:
      - scheduler
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

# ===================================
# VOLUMES
# ===================================
volumes:
  model_data:
    driver: local

# ===================================
# NETWORKS
# ===================================
networks:
  frontend-net:
    driver: bridge
  backend-net:
    driver: bridge
    internal: true # Isolate ML service from public access
